{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Investigación Corta #2 - Aprendizaje Supervisado\n",
    "\n",
    "\n",
    "### Escoger 6 métodos de aprendizaje supervisado, de forma tal que cumplan el siguiente esquema:\n",
    "\n",
    "* Cuatro métodos pueden ser de los que se analizaron en clase.\n",
    "* Dos metodos deben ser diferentes de los que se analizaron en clase.\n",
    "* Uno de los 2 metodos anteriores, debe ser de tipo “ensamble”.\n",
    "\n",
    "\n",
    "Dataset: https://datahub.io/machine-learning/musk#resource-musk_zip \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cuatro métodos pueden ser de los que se analizaron en clase.\n",
    "\n",
    "\n",
    "### 1. Linear Regresion \n",
    "### 2. kNN (k Nearest Neighbors) \n",
    "### 3. Naive Bayes\n",
    "### 4. Decision Trees\n",
    "\n",
    "\n",
    "A continuación mostraremos cada uno de los algoritmos utilizando el mismo set de Datos.\n",
    "\n",
    "Inicialmente se realizó la carga de los datos desde el archivo musk_csv.csv. De igual forma se realizó una limpieza de los datos para eliminar datos que no eran importantes en el análisis. Para nuestro caso se eliminó una tabla de indicadores que se encontraba repetida ya que era una cuenta del 1 hasta n.\n",
    "\n",
    "Por otro lado se limpió caracteres ya que en este caso utilizaremos el número de indicador como referencia para cada elemento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>f9</th>\n",
       "      <th>f10</th>\n",
       "      <th>...</th>\n",
       "      <th>f158</th>\n",
       "      <th>f159</th>\n",
       "      <th>f160</th>\n",
       "      <th>f161</th>\n",
       "      <th>f162</th>\n",
       "      <th>f163</th>\n",
       "      <th>f164</th>\n",
       "      <th>f165</th>\n",
       "      <th>f166</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6598.000000</td>\n",
       "      <td>6598.000000</td>\n",
       "      <td>6598.000000</td>\n",
       "      <td>6598.000000</td>\n",
       "      <td>6598.000000</td>\n",
       "      <td>6598.000000</td>\n",
       "      <td>6598.000000</td>\n",
       "      <td>6598.000000</td>\n",
       "      <td>6598.000000</td>\n",
       "      <td>6598.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>6598.000000</td>\n",
       "      <td>6598.000000</td>\n",
       "      <td>6598.000000</td>\n",
       "      <td>6598.000000</td>\n",
       "      <td>6598.000000</td>\n",
       "      <td>6598.000000</td>\n",
       "      <td>6598.000000</td>\n",
       "      <td>6598.000000</td>\n",
       "      <td>6598.000000</td>\n",
       "      <td>6598.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>58.945135</td>\n",
       "      <td>-119.128524</td>\n",
       "      <td>-73.146560</td>\n",
       "      <td>-0.628372</td>\n",
       "      <td>-103.533495</td>\n",
       "      <td>18.359806</td>\n",
       "      <td>-14.108821</td>\n",
       "      <td>-1.858290</td>\n",
       "      <td>-86.003031</td>\n",
       "      <td>-44.495756</td>\n",
       "      <td>...</td>\n",
       "      <td>-184.798272</td>\n",
       "      <td>-75.795696</td>\n",
       "      <td>-26.073204</td>\n",
       "      <td>64.616702</td>\n",
       "      <td>112.037739</td>\n",
       "      <td>201.760230</td>\n",
       "      <td>-47.488330</td>\n",
       "      <td>-150.259927</td>\n",
       "      <td>41.770233</td>\n",
       "      <td>0.154138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>53.249007</td>\n",
       "      <td>90.813375</td>\n",
       "      <td>67.956235</td>\n",
       "      <td>80.444617</td>\n",
       "      <td>64.387559</td>\n",
       "      <td>80.593655</td>\n",
       "      <td>115.315673</td>\n",
       "      <td>90.372537</td>\n",
       "      <td>108.326676</td>\n",
       "      <td>72.088903</td>\n",
       "      <td>...</td>\n",
       "      <td>107.819514</td>\n",
       "      <td>127.861271</td>\n",
       "      <td>69.727964</td>\n",
       "      <td>100.861935</td>\n",
       "      <td>72.835040</td>\n",
       "      <td>59.526751</td>\n",
       "      <td>55.069365</td>\n",
       "      <td>76.019023</td>\n",
       "      <td>94.116085</td>\n",
       "      <td>0.361108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-31.000000</td>\n",
       "      <td>-199.000000</td>\n",
       "      <td>-167.000000</td>\n",
       "      <td>-114.000000</td>\n",
       "      <td>-118.000000</td>\n",
       "      <td>-183.000000</td>\n",
       "      <td>-171.000000</td>\n",
       "      <td>-225.000000</td>\n",
       "      <td>-245.000000</td>\n",
       "      <td>-286.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-328.000000</td>\n",
       "      <td>-219.000000</td>\n",
       "      <td>-136.000000</td>\n",
       "      <td>-120.000000</td>\n",
       "      <td>-69.000000</td>\n",
       "      <td>73.000000</td>\n",
       "      <td>-289.000000</td>\n",
       "      <td>-428.000000</td>\n",
       "      <td>-471.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>37.000000</td>\n",
       "      <td>-193.000000</td>\n",
       "      <td>-137.000000</td>\n",
       "      <td>-70.000000</td>\n",
       "      <td>-117.000000</td>\n",
       "      <td>-28.000000</td>\n",
       "      <td>-159.000000</td>\n",
       "      <td>-85.000000</td>\n",
       "      <td>-217.000000</td>\n",
       "      <td>-96.750000</td>\n",
       "      <td>...</td>\n",
       "      <td>-272.000000</td>\n",
       "      <td>-205.000000</td>\n",
       "      <td>-70.000000</td>\n",
       "      <td>-18.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>166.000000</td>\n",
       "      <td>-68.000000</td>\n",
       "      <td>-179.000000</td>\n",
       "      <td>-9.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>44.000000</td>\n",
       "      <td>-149.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-25.000000</td>\n",
       "      <td>-117.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>-40.000000</td>\n",
       "      <td>-29.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-234.000000</td>\n",
       "      <td>-131.000000</td>\n",
       "      <td>-21.000000</td>\n",
       "      <td>61.500000</td>\n",
       "      <td>107.000000</td>\n",
       "      <td>191.000000</td>\n",
       "      <td>-60.000000</td>\n",
       "      <td>-150.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>53.000000</td>\n",
       "      <td>-95.000000</td>\n",
       "      <td>-19.000000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>-116.000000</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>-21.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-80.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>149.000000</td>\n",
       "      <td>129.000000</td>\n",
       "      <td>215.000000</td>\n",
       "      <td>-45.000000</td>\n",
       "      <td>-120.000000</td>\n",
       "      <td>119.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>292.000000</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>161.000000</td>\n",
       "      <td>325.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>220.000000</td>\n",
       "      <td>320.000000</td>\n",
       "      <td>147.000000</td>\n",
       "      <td>231.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>179.000000</td>\n",
       "      <td>192.000000</td>\n",
       "      <td>411.000000</td>\n",
       "      <td>355.000000</td>\n",
       "      <td>625.000000</td>\n",
       "      <td>295.000000</td>\n",
       "      <td>168.000000</td>\n",
       "      <td>367.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 167 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                f1           f2           f3           f4           f5  \\\n",
       "count  6598.000000  6598.000000  6598.000000  6598.000000  6598.000000   \n",
       "mean     58.945135  -119.128524   -73.146560    -0.628372  -103.533495   \n",
       "std      53.249007    90.813375    67.956235    80.444617    64.387559   \n",
       "min     -31.000000  -199.000000  -167.000000  -114.000000  -118.000000   \n",
       "25%      37.000000  -193.000000  -137.000000   -70.000000  -117.000000   \n",
       "50%      44.000000  -149.000000   -99.000000   -25.000000  -117.000000   \n",
       "75%      53.000000   -95.000000   -19.000000    42.000000  -116.000000   \n",
       "max     292.000000    95.000000    81.000000   161.000000   325.000000   \n",
       "\n",
       "                f6           f7           f8           f9          f10  ...  \\\n",
       "count  6598.000000  6598.000000  6598.000000  6598.000000  6598.000000  ...   \n",
       "mean     18.359806   -14.108821    -1.858290   -86.003031   -44.495756  ...   \n",
       "std      80.593655   115.315673    90.372537   108.326676    72.088903  ...   \n",
       "min    -183.000000  -171.000000  -225.000000  -245.000000  -286.000000  ...   \n",
       "25%     -28.000000  -159.000000   -85.000000  -217.000000   -96.750000  ...   \n",
       "50%      33.000000    27.000000    19.000000   -40.000000   -29.000000  ...   \n",
       "75%      74.000000    57.000000    61.000000   -21.000000     4.000000  ...   \n",
       "max     200.000000   220.000000   320.000000   147.000000   231.000000  ...   \n",
       "\n",
       "              f158         f159         f160         f161         f162  \\\n",
       "count  6598.000000  6598.000000  6598.000000  6598.000000  6598.000000   \n",
       "mean   -184.798272   -75.795696   -26.073204    64.616702   112.037739   \n",
       "std     107.819514   127.861271    69.727964   100.861935    72.835040   \n",
       "min    -328.000000  -219.000000  -136.000000  -120.000000   -69.000000   \n",
       "25%    -272.000000  -205.000000   -70.000000   -18.000000    71.000000   \n",
       "50%    -234.000000  -131.000000   -21.000000    61.500000   107.000000   \n",
       "75%     -80.000000    52.000000     9.000000   149.000000   129.000000   \n",
       "max      94.000000   179.000000   192.000000   411.000000   355.000000   \n",
       "\n",
       "              f163         f164         f165         f166        class  \n",
       "count  6598.000000  6598.000000  6598.000000  6598.000000  6598.000000  \n",
       "mean    201.760230   -47.488330  -150.259927    41.770233     0.154138  \n",
       "std      59.526751    55.069365    76.019023    94.116085     0.361108  \n",
       "min      73.000000  -289.000000  -428.000000  -471.000000     0.000000  \n",
       "25%     166.000000   -68.000000  -179.000000    -9.000000     0.000000  \n",
       "50%     191.000000   -60.000000  -150.000000    27.000000     0.000000  \n",
       "75%     215.000000   -45.000000  -120.000000   119.000000     0.000000  \n",
       "max     625.000000   295.000000   168.000000   367.000000     1.000000  \n",
       "\n",
       "[8 rows x 167 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Predict if a molecule, given the features, will be a musk or a non-musk.\n",
    "\n",
    "#https://www.openml.org/d/1116\n",
    "#https://datahub.io/machine-learning/musk#resource-musk_zip\n",
    "data_read= pd.read_csv('musk_csv.csv')\n",
    "\n",
    "df = pd.DataFrame(data_read)\n",
    "column_drop = df.drop(['ID','conformation_name', 'molecule_name'], axis=1)\n",
    "\n",
    "column_drop.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Linear Regresion\n",
    "\n",
    "También conocida como regresion lineal. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "Modification_2 = column_drop.head(2000)\n",
    "\n",
    "X = Modification_2.drop(columns=['class'])\n",
    "Y = Modification_2['class'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lr = LinearRegression().fit(X_train, y_train)\n",
    "\n",
    "print(\"Training set score: {:.2f}\".format(lr.score(X_train, y_train)))\n",
    "print(\"Test set score: {:.2f}\".format(lr.score(X_test, y_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split  \n",
    "from sklearn.metrics import classification_report, confusion_matrix \n",
    "\n",
    "X_trainSVM, X_testSVM, y_trainSVM, y_testSVM = train_test_split(X, Y, test_size = 0.20)  \n",
    "\n",
    "svclassifier = SVC(kernel='linear')  \n",
    "svclassifier.fit(X_trainSVM, y_trainSVM)  \n",
    "\n",
    "\n",
    "y_predSVM = svclassifier.predict(X_test) \n",
    "\n",
    "print(confusion_matrix(y_testSVM,y_predSVM))  \n",
    "print(classification_report(y_testSVM,y_predSVM))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. kNN (k Nearest Neighbors)\n",
    "\n",
    "Modelo supervisado en modelos de machine learning. Este trabaja tomando un dato y mirando sus 'k's más cercanos vecinos. Donde si los vecinos más cercanos son de alguna clasificación el elemento serpa parte de esta agrupación.\n",
    "\n",
    "Para el caso del Dataset que se está utilizando se usara para una clasificación. Ya que las salidas son \"0\" o \"1\".\n",
    "\n",
    "https://towardsdatascience.com/building-a-k-nearest-neighbors-k-nn-model-with-scikit-learn-51209555453a\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inicialmente se deben cargar las bibliotecas correspondientes como se muestra a continuación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se debe separa cuales son las entradas y cuáles son las salidas. Esto es posible eliminando la columna 'class' para definir las entradas y para definir las salidas se selecciona la columna 'class'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = column_drop.drop(columns=['class'])\n",
    "Y = column_drop['class'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test_size=0.35 Significa que el 35% sera usado para testing y 65% para training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.35, random_state=43)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se crean dos arreglos vacíos para el almacenamiento de los resultados del training y del test. Estos arreglos se dejaron en el mismo espacio de código para evitar que cuando se vuelva a ejecutar el for la cantidad de datos coincida cuando se genere el grafico.\n",
    "\n",
    "En el codigo se implementó un For para poder iterar varias veces con diferentes configuraciones/cantidades de vecinos esto para tener una mejor idea del valor adecuado para que no haya overfiting o underfiting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "training_accuracy = []\n",
    "test_accuracy1= []\n",
    "\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "neighbors_settings = range(1, 12)\n",
    "for n_neighbors in neighbors_settings:\n",
    "    # se construye el modelo de clasificacion\n",
    "    clf = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
    "    clf.fit(X_train,y_train)\n",
    "    # aca almacena el accuraci del training\"\n",
    "    training_accuracy.append(clf.score(X_train, y_train)) #\n",
    "    # se almacena la \"generalization accuracy\"\n",
    "    test_accuracy1.append(clf.score(X_test, y_test))\n",
    "plt.plot(neighbors_settings, training_accuracy, label=\"training accuracy\")\n",
    "plt.plot(neighbors_settings, test_accuracy1, label=\"test accuracy\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"n_neighbors\")\n",
    "plt.legend()\n",
    "print(n_neighbors)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Según el gráfico para una cantidad de vecinos entre 4 y 10 podríamos tener valores para evitar underfitting u overfitting. De igual forma la naturaleza de los datos utilizados se presta para seleccionar una menor cantidad de vecinos y se pueden obtener predicciones con una precisión aun mayor a 90%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Naive Bayes\n",
    "\n",
    "Es utilizado normalmente en Datasets grandes. En este caso es de aproximadamente de 6000 elementos con 168 Atributos.\n",
    "\n",
    "Primeramente se inicia con la carga de las Bibliotecas correspondientes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se realiza la separacion de cuales datos van a usarse como test y como de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, random_state=52)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este analisis se va a utilizar GaussianNB ya que estamos usando gran cantidad de datos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.815\n",
      "Test set score: 0.811\n"
     ]
    }
   ],
   "source": [
    "nbg = GaussianNB().fit(X_train, y_train)\n",
    "print(\"Training set score: {:.3f}\".format(nbg.score(X_train, y_train)))\n",
    "print(\"Test set score: {:.3f}\".format(nbg.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Durante la fase exploratoria de los resultados del entrenamiento se logró mejorar en 2% incrementando el valor de random_state a 52"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se realiza la separacion de cuales datos van a usarse como test y como de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.20, random_state=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "                       max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort=False,\n",
       "                       random_state=30, splitter='best')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = DecisionTreeClassifier(random_state=30)\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set: 1.000\n",
      "Accuracy on test set: 0.980\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy on training set: {:.3f}\".format(classifier.score(X_train, y_train)))\n",
    "print(\"Accuracy on test set: {:.3f}\".format(classifier.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esto indica que es un arbol puro esto debido al valor obtenido en el training set. Esto quiere decir que esta practicamente memorizando los datos de entrada ocasionando un overfit. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set: 0.918\n",
      "Accuracy on test set: 0.892\n"
     ]
    }
   ],
   "source": [
    "tree = DecisionTreeClassifier(max_depth=3, random_state=0)\n",
    "tree.fit(X_train, y_train)\n",
    "\n",
    "print(\"Accuracy on training set: {:.3f}\".format(tree.score(X_train, y_train)))\n",
    "print(\"Accuracy on test set: {:.3f}\".format(tree.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Limitando a solo 3 preguntas se logro disminuir el impacto de 'memorizar'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set: 0.995\n",
      "Accuracy on test set: 0.980\n"
     ]
    }
   ],
   "source": [
    "tree = DecisionTreeClassifier(min_samples_split=15, random_state=0)\n",
    "tree.fit(X_train, y_train)\n",
    "\n",
    "print(\"Accuracy on training set: {:.3f}\".format(tree.score(X_train, y_train)))\n",
    "print(\"Accuracy on test set: {:.3f}\".format(tree.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Se puede determinar el nivel de importancia de cada atributo con \"tree feature importances\" Pero como son tantos atributos prefiero no enlistarlos ni graficarlos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#print(\"Feature importances:\\n{}\".format(tree.feature_importances_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dos metodos deben ser diferentes de los que se analizaron en clase\n",
    "\n",
    "https://medium.com/@rrfd/boosting-bagging-and-stacking-ensemble-methods-with-sklearn-and-mlens-a455c0c982de\n",
    "\n",
    "\n",
    "combining predictions from several models averages out idiosyncratic errors and yield better overall predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Bagging classifier or Bootstrap Aggregation\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.BaggingClassifier.html\n",
    "\n",
    "\n",
    "Bootstrap is a sampling technique in which we select “n” observations out of a population of “n” observations. But the selection is entirely random, i.e., each observation can be chosen from the original population so that each observation is equally likely to be selected in each iteration of the bootstrapping process. After the bootstrapped samples are formed, separate models are trained with the bootstrapped samples. In real experiments, the bootstrapped samples are drawn from the training set, and the sub-models are tested using the testing set. The final output prediction is combined across the projections of all the sub-models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pre-Procesado\n",
    "\n",
    "Inicialmente limpiamos los datos provenientes del archivo .CSV ya que detecta 2 columnas adicionales con valores **'NaN'**. Adicionalmente se renombran las columnas con los nombres especificados en la fuente de obtencion de los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import model_selection\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "data_read= pd.read_csv('musk_csv.csv')\n",
    "\n",
    "df = pd.DataFrame(data_read)\n",
    "column_drop = df.drop(['ID','conformation_name', 'molecule_name'], axis=1)\n",
    "\n",
    "#column_drop.shape\n",
    "modified = column_drop.head(3500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into 70/30 train/test datasets and set up training variables\n",
    "#data_train,data_test=train_test_split(wine_df,test_size=0.30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2 = modified.drop(columns=['class'])\n",
    "Y2 = modified['class'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Control the number of n_estimators in ensemble functions\n",
    "#max_n_ests=25\n",
    "seed = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7734285714285715\n"
     ]
    }
   ],
   "source": [
    "kfold = model_selection.KFold(n_splits=10, random_state=seed)\n",
    "cart = DecisionTreeClassifier()\n",
    "num_trees = 100\n",
    "model = BaggingClassifier(base_estimator=cart, n_estimators=num_trees, random_state=seed)\n",
    "results = model_selection.cross_val_score(model, X2, Y2, cv=kfold)\n",
    "print(results.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. AdaBoost classifier\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "X3 = modified.drop(columns=['class'])\n",
    "Y3 = modified['class'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7762857142857142\n"
     ]
    }
   ],
   "source": [
    "seed = 7\n",
    "num_trees = 120\n",
    "kfold = model_selection.KFold(n_splits=10, random_state=seed)\n",
    "model = AdaBoostClassifier(n_estimators=num_trees, random_state=seed)\n",
    "results = model_selection.cross_val_score(model, X3, Y3, cv=kfold)\n",
    "print(results.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#seed = 7\n",
    "#num_trees_settings = range(1, 120)\n",
    "#for n_neighbors in [20, 35, 60, 80, 100, 120]:\n",
    "#    # se construye el modelo de clasificacion\n",
    "#    kfold = model_selection.KFold(n_splits=10, random_state=seed)\n",
    "#    model = AdaBoostClassifier(n_estimators=n_neighbors, random_state=seed)\n",
    "#        # se almacena el \"training set accuracy\"\n",
    "#    #clf.score(X_train, y_train)\n",
    "#    results = model_selection.cross_val_score(model, X3, Y3, cv=kfold)\n",
    "#    # se almacena la \"generalization accuracy\"\n",
    "    \n",
    "#plt.plot(n_neighbors, results, label=\"training accuracy\")\n",
    "#plt.plot(n_neighbors, test_accuracy1, label=\"test accuracy\")\n",
    "#plt.ylabel(\"Accuracy\")\n",
    "#plt.xlabel(\"n_neighbors\")\n",
    "#plt.legend()\n",
    "#print(n_neighbors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
